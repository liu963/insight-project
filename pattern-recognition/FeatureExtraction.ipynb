{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import iqr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label = 'no'\n",
    "label_out = 1 if label=='yes' else 0\n",
    "\n",
    "# directory = '../data/fields_raw_' + label + '/'\n",
    "directory = '../data/fields_raw_' + label + '_good/'\n",
    "# directory = '../data/fields_raw_' + label + '_clean/'\n",
    "\n",
    "for filein in os.listdir(directory):\n",
    "    if filein.endswith(\".png\"):\n",
    "        \n",
    "        # Load raw image, convert to grayscale\n",
    "        img = cv2.imread(directory + filein)\n",
    "        gray_raw = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Normalized\n",
    "        edge = 0\n",
    "        b, t = np.nanpercentile(gray_raw, [edge, 100 - edge])\n",
    "        gray_norm = 255*(gray_raw - b) / (t - b)\n",
    "\n",
    "        # Crop\n",
    "        length = gray_raw.shape[0]\n",
    "        width = gray_raw.shape[1]\n",
    "\n",
    "        frac = 0.05\n",
    "        x1 = int(frac*length)\n",
    "        x2 = length - int(frac*length)\n",
    "        y1 = int(frac*width)\n",
    "        y2 = width - int(frac*width)\n",
    "\n",
    "        cropped = gray_raw[x1:x2,y1:y2]\n",
    "\n",
    "        gray_raw = cropped\n",
    "\n",
    "        # Saturate scale based on percentiles\n",
    "        gray_nonzr = np.ravel(gray_raw[np.where(gray_raw!=np.min(gray_raw))])\n",
    "        gray_vec = np.ravel(gray_nonzr)\n",
    "\n",
    "        edge = 5  # percent\n",
    "        b, t = np.percentile(gray_vec, [edge, 100 - edge])\n",
    "\n",
    "        gray_sat = gray_raw.copy()\n",
    "        gray_sat[np.where(gray_sat<b)] = b\n",
    "        gray_sat[np.where(gray_sat>t)] = t\n",
    "\n",
    "        # Gaussian blur\n",
    "        blur = cv2.GaussianBlur(gray_sat,(3,3),0)\n",
    "\n",
    "        # Adaptive thresholding on saturated + Gaussian blur\n",
    "        thr_ad_blur = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,5,0)\n",
    "\n",
    "        # Calculate length of diagonal\n",
    "        diag = np.sqrt(thr_ad_blur.shape[0]**2+thr_ad_blur.shape[1]**2)\n",
    "\n",
    "        # Probabilistic Hough transform (detects line segments)\n",
    "\n",
    "        minLineLength = 20\n",
    "        maxLineGap = 1\n",
    "        lines_pr = cv2.HoughLinesP(thr_ad_blur,1,np.pi/180,10,minLineLength,maxLineGap)\n",
    "        # lines_pr = cv2.HoughLinesP(edges_ad_thr,1,np.pi/180,50,minLineLength,maxLineGap)\n",
    "        len(lines_pr)\n",
    "\n",
    "        # Get angles and lengths\n",
    "        thetas_pr = []\n",
    "        lengths_pr = []\n",
    "        for line in lines_pr.squeeze():\n",
    "            x1 = line[0]\n",
    "            y1 = line[1]\n",
    "            x2 = line[2]\n",
    "            y2 = line[3]\n",
    "            theta = np.arctan2(y2-y1,x2-x1)*180/ np.pi\n",
    "            thetas_pr.append(theta)\n",
    "            length = np.sqrt((x1-x2)**2 + (y1-y2)**2)\n",
    "            lengths_pr.append(length)\n",
    "        thetas_pr = np.array(thetas_pr)\n",
    "        lengths_pr = np.array(lengths_pr)\n",
    "\n",
    "        # feature for detecting if image contains patterns at all: \n",
    "        # spread in angle in line segments with similar length\n",
    "        thetas_pr_rad = thetas_pr\n",
    "        thetas_pr = np.abs(thetas_pr)\n",
    "\n",
    "        # k-means clustering\n",
    "        # feat = np.array([thetas_pr,lengths_pr]).T\n",
    "        feat = np.array([lengths_pr]).T\n",
    "        kmeans = KMeans(n_clusters=2).fit(feat)\n",
    "        labels = kmeans.labels_\n",
    "\n",
    "        # find cluster id that has the max length\n",
    "        good = labels[lengths_pr==np.max(lengths_pr)][0]\n",
    "\n",
    "        ix  = np.where(labels==good)\n",
    "        cluster_size = len(labels[ix])\n",
    "\n",
    "\n",
    "#         avglength  = np.mean(lengths_pr[ix])\n",
    "        avglength  = np.mean(lengths_pr[ix])/diag\n",
    "\n",
    "        stdangle  = np.std(thetas_pr[ix])\n",
    "\n",
    "#         medlength =  np.median(lengths_pr[ix])\n",
    "        medlength =  np.median(lengths_pr[ix])/diag\n",
    "\n",
    "        iqrangle  = iqr(thetas_pr[ix])\n",
    "        \n",
    "        top = np.percentile(lengths_pr,99)\n",
    "        iqrangle_top = iqr(thetas_pr[lengths_pr>=top])\n",
    "\n",
    "#         print (label_out,filein,cluster_size,avglength,medlength,stdangle,iqrangle,iqrangle_top10)\n",
    "\n",
    "        with open('labels_clean.txt','a') as f:\n",
    "            line = \"%i,%i,%f,%f,%f,%f,%f\\n\" % (label_out,cluster_size,avglength,medlength,stdangle,iqrangle,iqrangle_top)\n",
    "            f.write(line)\n",
    "\n",
    "#         with open('labels_top.txt','a') as f:\n",
    "#             line = \"%i,%i,%f,%f,%f,%f,%f\\n\" % (label_out,cluster_size,avglength,medlength,stdangle,iqrangle,iqrangle_top)\n",
    "#             f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
